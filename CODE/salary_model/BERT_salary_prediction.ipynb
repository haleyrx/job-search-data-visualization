{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CSE BERT salary prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3f694d3ca72e4c23ba6d86722d9a8772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7efa92eb5d184e0f9d266098880ad9ff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dee157aa4e6d4ad0b1390dcd83f64fb5",
              "IPY_MODEL_3c4310e1b8e04a32bc20253196d632b2"
            ]
          }
        },
        "7efa92eb5d184e0f9d266098880ad9ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dee157aa4e6d4ad0b1390dcd83f64fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fc34587a63ae4ec08da1afa165d550dc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ad45791c1af42ddb1a1d0f7416e49f7"
          }
        },
        "3c4310e1b8e04a32bc20253196d632b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a72cde0e39894e2b8070c850d49fd37a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:02&lt;00:00, 115kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f89664a75163428d925ad12dc89281fb"
          }
        },
        "fc34587a63ae4ec08da1afa165d550dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ad45791c1af42ddb1a1d0f7416e49f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a72cde0e39894e2b8070c850d49fd37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f89664a75163428d925ad12dc89281fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "404e22318ff74f4d986481f1c18cb80b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_91d3bed431074c1586d8464bd38a3528",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7721bc117c49471da9bd2a5ac721d216",
              "IPY_MODEL_f7c671759eca4befbc5db64b829571be"
            ]
          }
        },
        "91d3bed431074c1586d8464bd38a3528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7721bc117c49471da9bd2a5ac721d216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9611a60dbc2945c8ae7640adc6dcacab",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84880970e81a496299e677727d81b2d4"
          }
        },
        "f7c671759eca4befbc5db64b829571be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a2f1e15ac7964047a3cc459082d2c0b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 55.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b99373e8a18d44a983c04c06f9dc9f72"
          }
        },
        "9611a60dbc2945c8ae7640adc6dcacab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84880970e81a496299e677727d81b2d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2f1e15ac7964047a3cc459082d2c0b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b99373e8a18d44a983c04c06f9dc9f72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b141b2ae8f647b799c2b8929bee4416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d4fcfd2a024c46919a0cf809ab63a2b2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fabfb780e94b43d3b81e4dbaf5c0cf6c",
              "IPY_MODEL_d4de25c624a74a15bfc9f72f5d148c19"
            ]
          }
        },
        "d4fcfd2a024c46919a0cf809ab63a2b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fabfb780e94b43d3b81e4dbaf5c0cf6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6d3bab47b3e341dca466993f03a96eec",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6fd6fc6554144aa91cda7f831b48ac7"
          }
        },
        "d4de25c624a74a15bfc9f72f5d148c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_49c34e9852484fddbf224cfdab907b70",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.25MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32b78e20ee64414aab79e8f54b56ce86"
          }
        },
        "6d3bab47b3e341dca466993f03a96eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6fd6fc6554144aa91cda7f831b48ac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49c34e9852484fddbf224cfdab907b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32b78e20ee64414aab79e8f54b56ce86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c79e11120fc142ada5ec257cd9b75802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_059aeb2690d3458080a765a6b3433c9b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_56364c42b4c14751bf1b03b79fa46aa1",
              "IPY_MODEL_0cc35f1cbf4a46669face09fa0154d46"
            ]
          }
        },
        "059aeb2690d3458080a765a6b3433c9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56364c42b4c14751bf1b03b79fa46aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4483630ec3c340f088545b23b2e6670d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f9e092df8294942a4e1eec825a8fbea"
          }
        },
        "0cc35f1cbf4a46669face09fa0154d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_179a9ca5bc654e3ea70963dc30f27c17",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 853B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f3dc18bab8f4c73b0c4078f6b2faa49"
          }
        },
        "4483630ec3c340f088545b23b2e6670d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f9e092df8294942a4e1eec825a8fbea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "179a9ca5bc654e3ea70963dc30f27c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f3dc18bab8f4c73b0c4078f6b2faa49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aed5ea90282e4f81a238b1384433fd01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8425ed0c51ee4437ac7147e2fd9b5c88",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_92412e4ad8a843ddb70e724a4f44bda8",
              "IPY_MODEL_081288211a374aa1bcbfcd022fe0b51c"
            ]
          }
        },
        "8425ed0c51ee4437ac7147e2fd9b5c88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92412e4ad8a843ddb70e724a4f44bda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d38d51027e804edab4523a9ec65e0c76",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9170cf294094763a798784b0348000b"
          }
        },
        "081288211a374aa1bcbfcd022fe0b51c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_368e3c7c976b418eb6ad755d90e58774",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [03:01&lt;00:00, 2.43MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_edef9affb2f84d38aa65bda3525ff98f"
          }
        },
        "d38d51027e804edab4523a9ec65e0c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9170cf294094763a798784b0348000b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "368e3c7c976b418eb6ad755d90e58774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "edef9affb2f84d38aa65bda3525ff98f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_B6gT1EPCh-"
      },
      "source": [
        "# https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px45czxzNt0G",
        "outputId": "fef7e115-9004-4a75-e501-b4b24f8eb6ae"
      },
      "source": [
        "import tensorflow as tf\n",
        "seed_val = 42\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK9hPURiN63a",
        "outputId": "1e1cb4ad-da89-4a50-8120-9d22971b0dc8"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LEAhSTeN6pM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f019748e-3fd5-4dc3-877d-5abe6d27d0fd"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.1MB 9.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 21.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 60.4MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFlzdqBLN_Qd"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXejv9xNbEwd"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu6GcIXrpp32"
      },
      "source": [
        "import pickle\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKALplNH9TYw"
      },
      "source": [
        "import random\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "tf.random.set_seed(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlMSGfwzprDh"
      },
      "source": [
        "X = pd.read_csv(\"X.csv\")\n",
        "y = pd.read_csv(\"y.csv\")\n",
        "y[\"cat\"] = y.target.astype(\"category\")\n",
        "y[\"codes\"] = y[\"cat\"].cat.codes\n",
        "labels = y[\"codes\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynegXxYzN_WS"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=0, stratify = labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3qEmmP4N_YQ",
        "outputId": "b4fa4371-6d73-4dfa-cf80-9bb105f631a1"
      },
      "source": [
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(len(X_train)))\n",
        "print('Number of testing sentences: {:,}\\n'.format(len(X_test)))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "print(X_train.iloc[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 807\n",
            "\n",
            "Number of testing sentences: 202\n",
            "\n",
            "salary_type                                                Yearly\n",
            "company                                                     Jobot\n",
            "title                                   Technical Product Manager\n",
            "description     Technical Product Manager - Owner, C++ or Pyth...\n",
            "living_index                                                93.35\n",
            "Name: 834, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlJlaMDGN_aP"
      },
      "source": [
        "#df_train.loc[df_train.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zze9YetN_Mf"
      },
      "source": [
        "sentences = [d.salary_type + \" \" + str(d.living_index) + \" \"  + d.company + \" \" + d.title + \" \" + d.description for i, d in X_train.iterrows()]\n",
        "labels = [d for d in y_train]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8fD2BbGN_F1"
      },
      "source": [
        "from transformers import BertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183,
          "referenced_widgets": [
            "3f694d3ca72e4c23ba6d86722d9a8772",
            "7efa92eb5d184e0f9d266098880ad9ff",
            "dee157aa4e6d4ad0b1390dcd83f64fb5",
            "3c4310e1b8e04a32bc20253196d632b2",
            "fc34587a63ae4ec08da1afa165d550dc",
            "5ad45791c1af42ddb1a1d0f7416e49f7",
            "a72cde0e39894e2b8070c850d49fd37a",
            "f89664a75163428d925ad12dc89281fb",
            "404e22318ff74f4d986481f1c18cb80b",
            "91d3bed431074c1586d8464bd38a3528",
            "7721bc117c49471da9bd2a5ac721d216",
            "f7c671759eca4befbc5db64b829571be",
            "9611a60dbc2945c8ae7640adc6dcacab",
            "84880970e81a496299e677727d81b2d4",
            "a2f1e15ac7964047a3cc459082d2c0b8",
            "b99373e8a18d44a983c04c06f9dc9f72",
            "2b141b2ae8f647b799c2b8929bee4416",
            "d4fcfd2a024c46919a0cf809ab63a2b2",
            "fabfb780e94b43d3b81e4dbaf5c0cf6c",
            "d4de25c624a74a15bfc9f72f5d148c19",
            "6d3bab47b3e341dca466993f03a96eec",
            "d6fd6fc6554144aa91cda7f831b48ac7",
            "49c34e9852484fddbf224cfdab907b70",
            "32b78e20ee64414aab79e8f54b56ce86"
          ]
        },
        "id": "9TrJdRuEO503",
        "outputId": "c75c81c1-c6f7-4660-f7f3-e14aea2f3938"
      },
      "source": [
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f694d3ca72e4c23ba6d86722d9a8772",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "404e22318ff74f4d986481f1c18cb80b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b141b2ae8f647b799c2b8929bee4416",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W5GhlrzO5vS",
        "outputId": "5e555049-5241-473e-cc00-847db5f79b9c"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Yearly 93.35 Jobot Technical Product Manager Technical Product Manager - Owner, C++ or Python, API and/or SDK - Salary (DOE)\n",
            "\n",
            "This Jobot Job is hosted by: Nathan Duong\n",
            "Are you a fit? Easy Apply now by clicking the \"Apply On Company Site\" button and sending us your resume.\n",
            "Salary: $140,000 - $170,000\n",
            "\n",
            "A bit about us:\n",
            "---------\n",
            "\n",
            "Based near Redwood City, CA, we are the world's leading data analytics company that is revolutionizing the world with our full-service platform. We are a publicly-traded company with some of the biggest reputable investors. We help companies take their data and turn it into rich and useful information that our clients have used and thrust their way to the top!!! Just to give you some insight. We went from 600 - 1500 employees in one year, and we are planning to double in size by next!!! Due to exponentially rapid growth, we're looking for a solid and experienced Technical Project Manager to join the team.\n",
            "\n",
            "This candidate should have a strong understanding of C++/Python, has a past background in Software Development, and has good knowledge of API architecture and/or SDK Development. If this sounds like you, please apply to this amazing and career-changing opportunity!!!\n",
            "\n",
            "During these strange and rough times, we are continuing to move forward with our hiring efforts. While keeping conscious in regards to social distancing, we are conducting our interview process virtually. This is an IMMEDIATE need that you can land this job within 2 weeks!!!\n",
            "\n",
            "Why join us?\n",
            "---------\n",
            "\n",
            "We are a fantastic company that believes in taking care of its employees. If hired, you will be rewarded with an offer that will include\n",
            "\n",
            "Competitive Base Salary _ÑÐ (140K - 170K)\n",
            "Bonus\n",
            "Generous amounts of RSU's\n",
            "401K Match\n",
            "PAID Medical, dental, vision, Rx, 401k, FSAs, life insurance, disability insurance\n",
            "PTO\n",
            "Incredible job stability\n",
            "An amazing and fun working environment\n",
            "& other cool perks\n",
            "Why join us?\n",
            "\n",
            "Excellent Work/Life Balance.\n",
            "Tons of room for advancement\n",
            "Lots of upward mobility\n",
            "We work with cutting-edge technologies that keep our employees intellectually stimulated and professionally marketable.\n",
            "We operate in a Class A office environment and pride ourselves on cultivating a hospitable workspace for everyone to prosper.\n",
            "In addition to retaining employees by means of a hospitable, intellectually stimulating workplace we believe in compensating our people with aggressive compensation packages.\n",
            "We help our customers make the best decisions through data\n",
            "We get things done and for us, there is no such thing as mission impossible.\n",
            "Our clients are the world's biggest Specialty companies.\n",
            "\n",
            "Job Details\n",
            "---------\n",
            "\n",
            "Is your background a fit? Apply if you meet these criteria:\n",
            "Must have skills:\n",
            "Product Management\n",
            "Strong knowledge of C++ or Python\n",
            "Solid knowledge of API Architecture or SDK development\n",
            "Has a past background in Software Development\n",
            "\n",
            "What you will be doing:\n",
            "You will work with development teams to manage and organize large scope projects from the initial design concept phase - life cycle of products.\n",
            "Identify and help to convey the business value of product initiatives; collaborate with PM to kick off initiatives with development teams and enable the process to break those initiatives into a feature and user story-level requirements.\n",
            "Collaborate with development leaders to drive the planning process.\n",
            "Participate in development team formalities including story refinements, Standups, and team presentations to align the team towards a successful delivery cycle.\n",
            "Responsible for user story and feature acceptance on one or more development teams, where features or stories have customer-facing value.\n",
            "Collaborates with Product Managers to understand team developer goals and help prioritize initiatives strengthening those goals\n",
            "Manage, identify, and communicate initiative and highlight risks and dependencies across multiple teams\n",
            "Work with PM to review and respond to feedback via the Beta Program\n",
            "Work with QA and CST to prioritize the process of customer issues related to the project functionality\n",
            "Manage and monitor the successful delivery of features specified in the product roadmap with corresponding teams throughout the development life cycle.\n",
            "Works to identify risks and remove weaknesses.\n",
            "Discovers prospects for improvement and keeps Sr. management and others notified.\n",
            "Tokenized:  ['yearly', '93', '.', '35', 'job', '##ot', 'technical', 'product', 'manager', 'technical', 'product', 'manager', '-', 'owner', ',', 'c', '+', '+', 'or', 'python', ',', 'api', 'and', '/', 'or', 'sd', '##k', '-', 'salary', '(', 'doe', ')', 'this', 'job', '##ot', 'job', 'is', 'hosted', 'by', ':', 'nathan', 'duo', '##ng', 'are', 'you', 'a', 'fit', '?', 'easy', 'apply', 'now', 'by', 'clicking', 'the', '\"', 'apply', 'on', 'company', 'site', '\"', 'button', 'and', 'sending', 'us', 'your', 'resume', '.', 'salary', ':', '$', '140', ',', '000', '-', '$', '170', ',', '000', 'a', 'bit', 'about', 'us', ':', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'based', 'near', 'redwood', 'city', ',', 'ca', ',', 'we', 'are', 'the', 'world', \"'\", 's', 'leading', 'data', 'analytics', 'company', 'that', 'is', 'revolution', '##izing', 'the', 'world', 'with', 'our', 'full', '-', 'service', 'platform', '.', 'we', 'are', 'a', 'publicly', '-', 'traded', 'company', 'with', 'some', 'of', 'the', 'biggest', 'rep', '##utable', 'investors', '.', 'we', 'help', 'companies', 'take', 'their', 'data', 'and', 'turn', 'it', 'into', 'rich', 'and', 'useful', 'information', 'that', 'our', 'clients', 'have', 'used', 'and', 'thrust', 'their', 'way', 'to', 'the', 'top', '!', '!', '!', 'just', 'to', 'give', 'you', 'some', 'insight', '.', 'we', 'went', 'from', '600', '-', '1500', 'employees', 'in', 'one', 'year', ',', 'and', 'we', 'are', 'planning', 'to', 'double', 'in', 'size', 'by', 'next', '!', '!', '!', 'due', 'to', 'exponential', '##ly', 'rapid', 'growth', ',', 'we', \"'\", 're', 'looking', 'for', 'a', 'solid', 'and', 'experienced', 'technical', 'project', 'manager', 'to', 'join', 'the', 'team', '.', 'this', 'candidate', 'should', 'have', 'a', 'strong', 'understanding', 'of', 'c', '+', '+', '/', 'python', ',', 'has', 'a', 'past', 'background', 'in', 'software', 'development', ',', 'and', 'has', 'good', 'knowledge', 'of', 'api', 'architecture', 'and', '/', 'or', 'sd', '##k', 'development', '.', 'if', 'this', 'sounds', 'like', 'you', ',', 'please', 'apply', 'to', 'this', 'amazing', 'and', 'career', '-', 'changing', 'opportunity', '!', '!', '!', 'during', 'these', 'strange', 'and', 'rough', 'times', ',', 'we', 'are', 'continuing', 'to', 'move', 'forward', 'with', 'our', 'hiring', 'efforts', '.', 'while', 'keeping', 'conscious', 'in', 'regards', 'to', 'social', 'di', '##stan', '##cing', ',', 'we', 'are', 'conducting', 'our', 'interview', 'process', 'virtually', '.', 'this', 'is', 'an', 'immediate', 'need', 'that', 'you', 'can', 'land', 'this', 'job', 'within', '2', 'weeks', '!', '!', '!', 'why', 'join', 'us', '?', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'we', 'are', 'a', 'fantastic', 'company', 'that', 'believes', 'in', 'taking', 'care', 'of', 'its', 'employees', '.', 'if', 'hired', ',', 'you', 'will', 'be', 'rewarded', 'with', 'an', 'offer', 'that', 'will', 'include', 'competitive', 'base', 'salary', '_', 'n', '##ð', '(', '140', '##k', '-', '170', '##k', ')', 'bonus', 'generous', 'amounts', 'of', 'rs', '##u', \"'\", 's', '401', '##k', 'match', 'paid', 'medical', ',', 'dental', ',', 'vision', ',', 'r', '##x', ',', '401', '##k', ',', 'f', '##sas', ',', 'life', 'insurance', ',', 'disability', 'insurance', 'pt', '##o', 'incredible', 'job', 'stability', 'an', 'amazing', 'and', 'fun', 'working', 'environment', '&', 'other', 'cool', 'per', '##ks', 'why', 'join', 'us', '?', 'excellent', 'work', '/', 'life', 'balance', '.', 'tons', 'of', 'room', 'for', 'advancement', 'lots', 'of', 'upward', 'mobility', 'we', 'work', 'with', 'cutting', '-', 'edge', 'technologies', 'that', 'keep', 'our', 'employees', 'intellectual', '##ly', 'stimulated', 'and', 'professionally', 'market', '##able', '.', 'we', 'operate', 'in', 'a', 'class', 'a', 'office', 'environment', 'and', 'pride', 'ourselves', 'on', 'cult', '##ivating', 'a', 'ho', '##sp', '##ita', '##ble', 'works', '##pace', 'for', 'everyone', 'to', 'pro', '##sper', '.', 'in', 'addition', 'to', 'retaining', 'employees', 'by', 'means', 'of', 'a', 'ho', '##sp', '##ita', '##ble', ',', 'intellectual', '##ly', 'stimulating', 'workplace', 'we', 'believe', 'in', 'com', '##pen', '##sat', '##ing', 'our', 'people', 'with', 'aggressive', 'compensation', 'packages', '.', 'we', 'help', 'our', 'customers', 'make', 'the', 'best', 'decisions', 'through', 'data', 'we', 'get', 'things', 'done', 'and', 'for', 'us', ',', 'there', 'is', 'no', 'such', 'thing', 'as', 'mission', 'impossible', '.', 'our', 'clients', 'are', 'the', 'world', \"'\", 's', 'biggest', 'specialty', 'companies', '.', 'job', 'details', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'is', 'your', 'background', 'a', 'fit', '?', 'apply', 'if', 'you', 'meet', 'these', 'criteria', ':', 'must', 'have', 'skills', ':', 'product', 'management', 'strong', 'knowledge', 'of', 'c', '+', '+', 'or', 'python', 'solid', 'knowledge', 'of', 'api', 'architecture', 'or', 'sd', '##k', 'development', 'has', 'a', 'past', 'background', 'in', 'software', 'development', 'what', 'you', 'will', 'be', 'doing', ':', 'you', 'will', 'work', 'with', 'development', 'teams', 'to', 'manage', 'and', 'organize', 'large', 'scope', 'projects', 'from', 'the', 'initial', 'design', 'concept', 'phase', '-', 'life', 'cycle', 'of', 'products', '.', 'identify', 'and', 'help', 'to', 'convey', 'the', 'business', 'value', 'of', 'product', 'initiatives', ';', 'collaborate', 'with', 'pm', 'to', 'kick', 'off', 'initiatives', 'with', 'development', 'teams', 'and', 'enable', 'the', 'process', 'to', 'break', 'those', 'initiatives', 'into', 'a', 'feature', 'and', 'user', 'story', '-', 'level', 'requirements', '.', 'collaborate', 'with', 'development', 'leaders', 'to', 'drive', 'the', 'planning', 'process', '.', 'participate', 'in', 'development', 'team', 'formal', '##ities', 'including', 'story', 'ref', '##ine', '##ments', ',', 'stand', '##ups', ',', 'and', 'team', 'presentations', 'to', 'align', 'the', 'team', 'towards', 'a', 'successful', 'delivery', 'cycle', '.', 'responsible', 'for', 'user', 'story', 'and', 'feature', 'acceptance', 'on', 'one', 'or', 'more', 'development', 'teams', ',', 'where', 'features', 'or', 'stories', 'have', 'customer', '-', 'facing', 'value', '.', 'collaborate', '##s', 'with', 'product', 'managers', 'to', 'understand', 'team', 'developer', 'goals', 'and', 'help', 'prior', '##iti', '##ze', 'initiatives', 'strengthening', 'those', 'goals', 'manage', ',', 'identify', ',', 'and', 'communicate', 'initiative', 'and', 'highlight', 'risks', 'and', 'depend', '##encies', 'across', 'multiple', 'teams', 'work', 'with', 'pm', 'to', 'review', 'and', 'respond', 'to', 'feedback', 'via', 'the', 'beta', 'program', 'work', 'with', 'q', '##a', 'and', 'cs', '##t', 'to', 'prior', '##iti', '##ze', 'the', 'process', 'of', 'customer', 'issues', 'related', 'to', 'the', 'project', 'functionality', 'manage', 'and', 'monitor', 'the', 'successful', 'delivery', 'of', 'features', 'specified', 'in', 'the', 'product', 'road', '##ma', '##p', 'with', 'corresponding', 'teams', 'throughout', 'the', 'development', 'life', 'cycle', '.', 'works', 'to', 'identify', 'risks', 'and', 'remove', 'weaknesses', '.', 'discovers', 'prospects', 'for', 'improvement', 'and', 'keeps', 'sr', '.', 'management', 'and', 'others', 'notified', '.']\n",
            "Token IDs:  [12142, 6109, 1012, 3486, 3105, 4140, 4087, 4031, 3208, 4087, 4031, 3208, 1011, 3954, 1010, 1039, 1009, 1009, 2030, 18750, 1010, 17928, 1998, 1013, 2030, 17371, 2243, 1011, 10300, 1006, 18629, 1007, 2023, 3105, 4140, 3105, 2003, 4354, 2011, 1024, 7150, 6829, 3070, 2024, 2017, 1037, 4906, 1029, 3733, 6611, 2085, 2011, 22042, 1996, 1000, 6611, 2006, 2194, 2609, 1000, 6462, 1998, 6016, 2149, 2115, 13746, 1012, 10300, 1024, 1002, 8574, 1010, 2199, 1011, 1002, 10894, 1010, 2199, 1037, 2978, 2055, 2149, 1024, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 2241, 2379, 27552, 2103, 1010, 6187, 1010, 2057, 2024, 1996, 2088, 1005, 1055, 2877, 2951, 25095, 2194, 2008, 2003, 4329, 6026, 1996, 2088, 2007, 2256, 2440, 1011, 2326, 4132, 1012, 2057, 2024, 1037, 7271, 1011, 7007, 2194, 2007, 2070, 1997, 1996, 5221, 16360, 23056, 9387, 1012, 2057, 2393, 3316, 2202, 2037, 2951, 1998, 2735, 2009, 2046, 4138, 1998, 6179, 2592, 2008, 2256, 7846, 2031, 2109, 1998, 7400, 2037, 2126, 2000, 1996, 2327, 999, 999, 999, 2074, 2000, 2507, 2017, 2070, 12369, 1012, 2057, 2253, 2013, 5174, 1011, 10347, 5126, 1999, 2028, 2095, 1010, 1998, 2057, 2024, 4041, 2000, 3313, 1999, 2946, 2011, 2279, 999, 999, 999, 2349, 2000, 27258, 2135, 5915, 3930, 1010, 2057, 1005, 2128, 2559, 2005, 1037, 5024, 1998, 5281, 4087, 2622, 3208, 2000, 3693, 1996, 2136, 1012, 2023, 4018, 2323, 2031, 1037, 2844, 4824, 1997, 1039, 1009, 1009, 1013, 18750, 1010, 2038, 1037, 2627, 4281, 1999, 4007, 2458, 1010, 1998, 2038, 2204, 3716, 1997, 17928, 4294, 1998, 1013, 2030, 17371, 2243, 2458, 1012, 2065, 2023, 4165, 2066, 2017, 1010, 3531, 6611, 2000, 2023, 6429, 1998, 2476, 1011, 5278, 4495, 999, 999, 999, 2076, 2122, 4326, 1998, 5931, 2335, 1010, 2057, 2024, 5719, 2000, 2693, 2830, 2007, 2256, 14763, 4073, 1012, 2096, 4363, 9715, 1999, 12362, 2000, 2591, 4487, 12693, 6129, 1010, 2057, 2024, 9283, 2256, 4357, 2832, 8990, 1012, 2023, 2003, 2019, 6234, 2342, 2008, 2017, 2064, 2455, 2023, 3105, 2306, 1016, 3134, 999, 999, 999, 2339, 3693, 2149, 1029, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 2057, 2024, 1037, 10392, 2194, 2008, 7164, 1999, 2635, 2729, 1997, 2049, 5126, 1012, 2065, 5086, 1010, 2017, 2097, 2022, 14610, 2007, 2019, 3749, 2008, 2097, 2421, 6975, 2918, 10300, 1035, 1050, 29668, 1006, 8574, 2243, 1011, 10894, 2243, 1007, 6781, 12382, 8310, 1997, 12667, 2226, 1005, 1055, 22649, 2243, 2674, 3825, 2966, 1010, 11394, 1010, 4432, 1010, 1054, 2595, 1010, 22649, 2243, 1010, 1042, 20939, 1010, 2166, 5427, 1010, 11980, 5427, 13866, 2080, 9788, 3105, 9211, 2019, 6429, 1998, 4569, 2551, 4044, 1004, 2060, 4658, 2566, 5705, 2339, 3693, 2149, 1029, 6581, 2147, 1013, 2166, 5703, 1012, 6197, 1997, 2282, 2005, 12607, 7167, 1997, 10745, 12969, 2057, 2147, 2007, 6276, 1011, 3341, 6786, 2008, 2562, 2256, 5126, 7789, 2135, 25194, 1998, 12145, 3006, 3085, 1012, 2057, 5452, 1999, 1037, 2465, 1037, 2436, 4044, 1998, 6620, 9731, 2006, 8754, 17441, 1037, 7570, 13102, 6590, 3468, 2573, 15327, 2005, 3071, 2000, 4013, 17668, 1012, 1999, 2804, 2000, 12823, 5126, 2011, 2965, 1997, 1037, 7570, 13102, 6590, 3468, 1010, 7789, 2135, 27295, 16165, 2057, 2903, 1999, 4012, 11837, 16846, 2075, 2256, 2111, 2007, 9376, 9430, 14555, 1012, 2057, 2393, 2256, 6304, 2191, 1996, 2190, 6567, 2083, 2951, 2057, 2131, 2477, 2589, 1998, 2005, 2149, 1010, 2045, 2003, 2053, 2107, 2518, 2004, 3260, 5263, 1012, 2256, 7846, 2024, 1996, 2088, 1005, 1055, 5221, 12233, 3316, 1012, 3105, 4751, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 2003, 2115, 4281, 1037, 4906, 1029, 6611, 2065, 2017, 3113, 2122, 9181, 1024, 2442, 2031, 4813, 1024, 4031, 2968, 2844, 3716, 1997, 1039, 1009, 1009, 2030, 18750, 5024, 3716, 1997, 17928, 4294, 2030, 17371, 2243, 2458, 2038, 1037, 2627, 4281, 1999, 4007, 2458, 2054, 2017, 2097, 2022, 2725, 1024, 2017, 2097, 2147, 2007, 2458, 2780, 2000, 6133, 1998, 10939, 2312, 9531, 3934, 2013, 1996, 3988, 2640, 4145, 4403, 1011, 2166, 5402, 1997, 3688, 1012, 6709, 1998, 2393, 2000, 16636, 1996, 2449, 3643, 1997, 4031, 11107, 1025, 20880, 2007, 7610, 2000, 5926, 2125, 11107, 2007, 2458, 2780, 1998, 9585, 1996, 2832, 2000, 3338, 2216, 11107, 2046, 1037, 3444, 1998, 5310, 2466, 1011, 2504, 5918, 1012, 20880, 2007, 2458, 4177, 2000, 3298, 1996, 4041, 2832, 1012, 5589, 1999, 2458, 2136, 5337, 6447, 2164, 2466, 25416, 3170, 8163, 1010, 3233, 22264, 1010, 1998, 2136, 18216, 2000, 25705, 1996, 2136, 2875, 1037, 3144, 6959, 5402, 1012, 3625, 2005, 5310, 2466, 1998, 3444, 9920, 2006, 2028, 2030, 2062, 2458, 2780, 1010, 2073, 2838, 2030, 3441, 2031, 8013, 1011, 5307, 3643, 1012, 20880, 2015, 2007, 4031, 10489, 2000, 3305, 2136, 9722, 3289, 1998, 2393, 3188, 25090, 4371, 11107, 16003, 2216, 3289, 6133, 1010, 6709, 1010, 1998, 10639, 6349, 1998, 12944, 10831, 1998, 12530, 15266, 2408, 3674, 2780, 2147, 2007, 7610, 2000, 3319, 1998, 6869, 2000, 12247, 3081, 1996, 8247, 2565, 2147, 2007, 1053, 2050, 1998, 20116, 2102, 2000, 3188, 25090, 4371, 1996, 2832, 1997, 8013, 3314, 3141, 2000, 1996, 2622, 15380, 6133, 1998, 8080, 1996, 3144, 6959, 1997, 2838, 9675, 1999, 1996, 4031, 2346, 2863, 2361, 2007, 7978, 2780, 2802, 1996, 2458, 2166, 5402, 1012, 2573, 2000, 6709, 10831, 1998, 6366, 21775, 1012, 9418, 16746, 2005, 7620, 1998, 7906, 5034, 1012, 2968, 1998, 2500, 19488, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRxsm3K6O5qh",
        "outputId": "9fd3d74f-bd0e-42b1-874f-f6134ae8f35e"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        max_length = 300,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Yearly 93.35 Jobot Technical Product Manager Technical Product Manager - Owner, C++ or Python, API and/or SDK - Salary (DOE)\n",
            "\n",
            "This Jobot Job is hosted by: Nathan Duong\n",
            "Are you a fit? Easy Apply now by clicking the \"Apply On Company Site\" button and sending us your resume.\n",
            "Salary: $140,000 - $170,000\n",
            "\n",
            "A bit about us:\n",
            "---------\n",
            "\n",
            "Based near Redwood City, CA, we are the world's leading data analytics company that is revolutionizing the world with our full-service platform. We are a publicly-traded company with some of the biggest reputable investors. We help companies take their data and turn it into rich and useful information that our clients have used and thrust their way to the top!!! Just to give you some insight. We went from 600 - 1500 employees in one year, and we are planning to double in size by next!!! Due to exponentially rapid growth, we're looking for a solid and experienced Technical Project Manager to join the team.\n",
            "\n",
            "This candidate should have a strong understanding of C++/Python, has a past background in Software Development, and has good knowledge of API architecture and/or SDK Development. If this sounds like you, please apply to this amazing and career-changing opportunity!!!\n",
            "\n",
            "During these strange and rough times, we are continuing to move forward with our hiring efforts. While keeping conscious in regards to social distancing, we are conducting our interview process virtually. This is an IMMEDIATE need that you can land this job within 2 weeks!!!\n",
            "\n",
            "Why join us?\n",
            "---------\n",
            "\n",
            "We are a fantastic company that believes in taking care of its employees. If hired, you will be rewarded with an offer that will include\n",
            "\n",
            "Competitive Base Salary _ÑÐ (140K - 170K)\n",
            "Bonus\n",
            "Generous amounts of RSU's\n",
            "401K Match\n",
            "PAID Medical, dental, vision, Rx, 401k, FSAs, life insurance, disability insurance\n",
            "PTO\n",
            "Incredible job stability\n",
            "An amazing and fun working environment\n",
            "& other cool perks\n",
            "Why join us?\n",
            "\n",
            "Excellent Work/Life Balance.\n",
            "Tons of room for advancement\n",
            "Lots of upward mobility\n",
            "We work with cutting-edge technologies that keep our employees intellectually stimulated and professionally marketable.\n",
            "We operate in a Class A office environment and pride ourselves on cultivating a hospitable workspace for everyone to prosper.\n",
            "In addition to retaining employees by means of a hospitable, intellectually stimulating workplace we believe in compensating our people with aggressive compensation packages.\n",
            "We help our customers make the best decisions through data\n",
            "We get things done and for us, there is no such thing as mission impossible.\n",
            "Our clients are the world's biggest Specialty companies.\n",
            "\n",
            "Job Details\n",
            "---------\n",
            "\n",
            "Is your background a fit? Apply if you meet these criteria:\n",
            "Must have skills:\n",
            "Product Management\n",
            "Strong knowledge of C++ or Python\n",
            "Solid knowledge of API Architecture or SDK development\n",
            "Has a past background in Software Development\n",
            "\n",
            "What you will be doing:\n",
            "You will work with development teams to manage and organize large scope projects from the initial design concept phase - life cycle of products.\n",
            "Identify and help to convey the business value of product initiatives; collaborate with PM to kick off initiatives with development teams and enable the process to break those initiatives into a feature and user story-level requirements.\n",
            "Collaborate with development leaders to drive the planning process.\n",
            "Participate in development team formalities including story refinements, Standups, and team presentations to align the team towards a successful delivery cycle.\n",
            "Responsible for user story and feature acceptance on one or more development teams, where features or stories have customer-facing value.\n",
            "Collaborates with Product Managers to understand team developer goals and help prioritize initiatives strengthening those goals\n",
            "Manage, identify, and communicate initiative and highlight risks and dependencies across multiple teams\n",
            "Work with PM to review and respond to feedback via the Beta Program\n",
            "Work with QA and CST to prioritize the process of customer issues related to the project functionality\n",
            "Manage and monitor the successful delivery of features specified in the product roadmap with corresponding teams throughout the development life cycle.\n",
            "Works to identify risks and remove weaknesses.\n",
            "Discovers prospects for improvement and keeps Sr. management and others notified.\n",
            "Token IDs: [101, 12142, 6109, 1012, 3486, 3105, 4140, 4087, 4031, 3208, 4087, 4031, 3208, 1011, 3954, 1010, 1039, 1009, 1009, 2030, 18750, 1010, 17928, 1998, 1013, 2030, 17371, 2243, 1011, 10300, 1006, 18629, 1007, 2023, 3105, 4140, 3105, 2003, 4354, 2011, 1024, 7150, 6829, 3070, 2024, 2017, 1037, 4906, 1029, 3733, 6611, 2085, 2011, 22042, 1996, 1000, 6611, 2006, 2194, 2609, 1000, 6462, 1998, 6016, 2149, 2115, 13746, 1012, 10300, 1024, 1002, 8574, 1010, 2199, 1011, 1002, 10894, 1010, 2199, 1037, 2978, 2055, 2149, 1024, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 2241, 2379, 27552, 2103, 1010, 6187, 1010, 2057, 2024, 1996, 2088, 1005, 1055, 2877, 2951, 25095, 2194, 2008, 2003, 4329, 6026, 1996, 2088, 2007, 2256, 2440, 1011, 2326, 4132, 1012, 2057, 2024, 1037, 7271, 1011, 7007, 2194, 2007, 2070, 1997, 1996, 5221, 16360, 23056, 9387, 1012, 2057, 2393, 3316, 2202, 2037, 2951, 1998, 2735, 2009, 2046, 4138, 1998, 6179, 2592, 2008, 2256, 7846, 2031, 2109, 1998, 7400, 2037, 2126, 2000, 1996, 2327, 999, 999, 999, 2074, 2000, 2507, 2017, 2070, 12369, 1012, 2057, 2253, 2013, 5174, 1011, 10347, 5126, 1999, 2028, 2095, 1010, 1998, 2057, 2024, 4041, 2000, 3313, 1999, 2946, 2011, 2279, 999, 999, 999, 2349, 2000, 27258, 2135, 5915, 3930, 1010, 2057, 1005, 2128, 2559, 2005, 1037, 5024, 1998, 5281, 4087, 2622, 3208, 2000, 3693, 1996, 2136, 1012, 2023, 4018, 2323, 2031, 1037, 2844, 4824, 1997, 1039, 1009, 1009, 1013, 18750, 1010, 2038, 1037, 2627, 4281, 1999, 4007, 2458, 1010, 1998, 2038, 2204, 3716, 1997, 17928, 4294, 1998, 1013, 2030, 17371, 2243, 2458, 1012, 2065, 2023, 4165, 2066, 2017, 1010, 3531, 6611, 2000, 2023, 6429, 1998, 2476, 1011, 5278, 4495, 999, 999, 999, 2076, 2122, 4326, 1998, 5931, 2335, 1010, 2057, 2024, 5719, 2000, 2693, 2830, 2007, 2256, 14763, 4073, 1012, 2096, 4363, 9715, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSKsNJDlO5k9",
        "outputId": "82665253-2dc3-4151-daf0-d59565f7376a"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZSO3zOlPR3a"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-Y9rg8VO5fL",
        "outputId": "3267d22e-70c6-479b-f9a5-d4e3224acaa6"
      },
      "source": [
        "# Set the maximum sequence length.\n",
        "# I've chosen 400 somewhat arbitrarily. These can be quite long\n",
        "MAX_LEN = 300\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 300 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKmd9nF5O5YN"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gnakjAmPZ3c"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnFcuCCGO5R7"
      },
      "source": [
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.2)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_tXbSYUPrhV"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQvVnGpnO5Kk"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIO79e4HPeIj"
      },
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 16\n",
        "# batch_size = 8\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8r8H0bMPeFg"
      },
      "source": [
        "from transformers import RobertaForSequenceClassification, BertForSequenceClassification, AdamW, BertConfig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c79e11120fc142ada5ec257cd9b75802",
            "059aeb2690d3458080a765a6b3433c9b",
            "56364c42b4c14751bf1b03b79fa46aa1",
            "0cc35f1cbf4a46669face09fa0154d46",
            "4483630ec3c340f088545b23b2e6670d",
            "6f9e092df8294942a4e1eec825a8fbea",
            "179a9ca5bc654e3ea70963dc30f27c17",
            "2f3dc18bab8f4c73b0c4078f6b2faa49",
            "aed5ea90282e4f81a238b1384433fd01",
            "8425ed0c51ee4437ac7147e2fd9b5c88",
            "92412e4ad8a843ddb70e724a4f44bda8",
            "081288211a374aa1bcbfcd022fe0b51c",
            "d38d51027e804edab4523a9ec65e0c76",
            "a9170cf294094763a798784b0348000b",
            "368e3c7c976b418eb6ad755d90e58774",
            "edef9affb2f84d38aa65bda3525ff98f"
          ]
        },
        "id": "0L6Cz96mPd_V",
        "outputId": "fe18488a-c407-49e2-a91c-a2f22459431d"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 5, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c79e11120fc142ada5ec257cd9b75802",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aed5ea90282e4f81a238b1384433fd01",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxT2fvJcPd8F",
        "outputId": "ea045e98-2f4c-4dca-e4a8-6e8132a2f125"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (5, 768)\n",
            "classifier.bias                                                 (5,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDkF6zR1Pd4S"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  # lr = 2e-6, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  # eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNhpxTTKPdzJ"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnzApLonQFLb"
      },
      "source": [
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "# epochs = 6\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yPdADGaQGrS"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l3bQRzMPdo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690d1555-a9ba-47b0-c01e-fbecbbc68bae"
      },
      "source": [
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device).long()\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     41.    Elapsed: 0:00:34.\n",
            "\n",
            "  Average training loss: 1.60\n",
            "  Training epoch took: 0:00:35\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.32\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     41.    Elapsed: 0:00:37.\n",
            "\n",
            "  Average training loss: 1.52\n",
            "  Training epoch took: 0:00:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.32\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     41.    Elapsed: 0:00:37.\n",
            "\n",
            "  Average training loss: 1.37\n",
            "  Training epoch took: 0:00:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.36\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     41.    Elapsed: 0:00:37.\n",
            "\n",
            "  Average training loss: 1.24\n",
            "  Training epoch took: 0:00:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.36\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dngD-KHyQReb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txUQ4y1_O5Cr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "211628f7-0b90-4482-ec55-fd79fc624c28"
      },
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJlKYpraVg-t"
      },
      "source": [
        "# TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltNBRkYlVg2n",
        "outputId": "41b9f6e0-f2db-46ba-8429-588b12845490"
      },
      "source": [
        "# Put model in evaluation mode\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKra8XEJdyhv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77fdcec5-8e95-43bd-cd88-bd8fc1d0f71a"
      },
      "source": [
        "# Report the number of sentences.\n",
        "# print('Number of test sentences: {:,}\\n'.format(df_test.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "# sentences = df_test.sentence.values\n",
        "# labels = df_test.label.values\n",
        "# sentences = [d[0] for d in df_test]\n",
        "# labels = [int(d[1]) for d in df_test]\n",
        "sentences = [d.salary_type + \" \" + str(d.living_index) + \" \"  + d.company + \" \" + d.title + \" \" + d.description for i, d in X_test.iterrows()]\n",
        "labels = [d for d in y_test]\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 16 \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXo_Qrj7WE58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ccbe76-e64b-4b22-92f1-3a21122aea4b"
      },
      "source": [
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqIVZbDtWqVe"
      },
      "source": [
        "TEST_PREDICTION_VALUES = []\n",
        "TEST_TRUTH_VALUES = []\n",
        "for i in range(len(predictions)):\n",
        "  this_batch_predictions = np.argmax(predictions[i], axis=1).flatten()\n",
        "  TEST_PREDICTION_VALUES.extend(this_batch_predictions)\n",
        "  TEST_TRUTH_VALUES.extend(true_labels[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6QnppzJ8K5a"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdFrShwx_I4g"
      },
      "source": [
        "mapping = {\n",
        "    3:\"120K - 150K\",\n",
        "    1:\"60K - 90K\",\n",
        "    2:\"90K - 120K\",\n",
        "    0:\"<60K\",\n",
        "    4:\">150K\",\n",
        "}\n",
        "tt = [mapping[t] for t in TEST_TRUTH_VALUES]\n",
        "tp = [mapping[t] for t in TEST_PREDICTION_VALUES]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P_rWZF3_qyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2176294b-ef68-4330-972c-6181c51545c4"
      },
      "source": [
        "print(classification_report(tt, tp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " 120K - 150K       0.55      0.49      0.52        45\n",
            "   60K - 90K       0.25      0.20      0.22        41\n",
            "  90K - 120K       0.00      0.00      0.00        31\n",
            "        <60K       0.33      0.57      0.42        47\n",
            "       >150K       0.44      0.55      0.49        38\n",
            "\n",
            "    accuracy                           0.39       202\n",
            "   macro avg       0.31      0.36      0.33       202\n",
            "weighted avg       0.33      0.39      0.35       202\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSyXgzzp8L4y",
        "outputId": "26569faf-cf00-415e-a1cc-030ef8cbbc4a"
      },
      "source": [
        "print(classification_report(TEST_TRUTH_VALUES, TEST_PREDICTION_VALUES))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.57      0.42        47\n",
            "           1       0.25      0.20      0.22        41\n",
            "           2       0.00      0.00      0.00        31\n",
            "           3       0.55      0.49      0.52        45\n",
            "           4       0.44      0.55      0.49        38\n",
            "\n",
            "    accuracy                           0.39       202\n",
            "   macro avg       0.31      0.36      0.33       202\n",
            "weighted avg       0.33      0.39      0.35       202\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E18uxSj0WEoN"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, roc_curve, auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSqaQu7VFmlL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8fSyaFyOB6T",
        "outputId": "1ea3a3e8-755f-4450-8013-36281c06bbfa"
      },
      "source": [
        "accuracy_score(TEST_TRUTH_VALUES, TEST_PREDICTION_VALUES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38613861386138615"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkfffw4W9BgF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}